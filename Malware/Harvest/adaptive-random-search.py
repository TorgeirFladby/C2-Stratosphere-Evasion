import numpy as np
import random


class PerturbationOptimizer:

    def __init__(self,
        problem_size = 2,
        max_iter = 1000,
        bounds = [[300, 400], [1000, 2000], [5000, 12000]],
        init_factor_bytes = 0.1,
        init_factor_duration = 0.1,
        init_factor_offline = 0.9,
        s_factor = 1.2,
        l_factor = 3.0,
        iter_mult = 10,
        max_no_impr = 20):
        self.problem_size = problem_size
        self.bounds = bounds
        self.max_iter = max_iter
        self.init_factor_bytes = init_factor_bytes
        self.init_factor_duration = init_factor_duration
        self.init_factor_offline = init_factor_offline
        self.s_factor = s_factor
        self.l_factor = l_factor
        self.iter_mult = iter_mult
        self.max_no_impr = max_no_impr

        self.best = self.adaptive_random_search(
            self.max_iter,
            self.bounds,
            self.init_factor_bytes,
            self.init_factor_duration,
            self.init_factor_offline,
            self.s_factor,
            self.l_factor,
            self.iter_mult,
            self.max_no_impr
        )


    def objective_function(self, vector, pert_vector=None):
        return (vector[2] + vector[1])/vector[0]

    def random_vector(self, minmax):
        """
        Returns a random 2D vector that represents a step in a random direction, based on thresholds.
        """
        return [self.rand_in_bounds(minmax[i][0], minmax[i][1]) for i in range(len(minmax))]


    def rand_in_bounds(self, min, max):
        return min + ((max-min) * random.uniform(0, 1))

    def large_step_size(self, iter, step_size, s_factor, l_factor, iter_mult):
        if iter > 0 and iter % iter_mult == 0:
            return [x * l_factor for x in step_size]
        return [x * s_factor for x in step_size]

    def take_steps(self, bounds, current, step_size, big_stepsize):
        step, big_step = {}, {}
        step["vector"] = self.take_step(bounds, current["vector"], step_size)
        step["cost"] = self.objective_function(step["vector"])
        big_step["vector"] = self.take_step(bounds, current["vector"], big_stepsize)
        big_step["cost"] = self.objective_function(big_step["vector"])

        return step, big_step

    def take_step(self, minmax, current, step_size):
        position = current
        for i in range(len(position)):
            min_i = max(minmax[i][0], current[i]-step_size[i])
            max_i = min(minmax[i][1], current[i]+step_size[i])
            position[i] = self.rand_in_bounds(min_i, max_i)
        return position

    def adaptive_random_search(self,
        max_iter=100,
        bounds=[[300, 400], [1000, 2000], [5000, 12000]],
        init_factor_bytes=0.1,
        init_factor_duration=0.1,
        init_factor_offline=0.9,
        s_factor=1.2,
        l_factor=3.0,
        iter_mult=10,
        max_no_impr=10):
        """
        Description:
            Init function for the Adaptive Random Search algorithm

        Args:
            max_iter: the maximum amount of iterations one session will conduct.
            bounds: 2D list representing the bounds for each parameter on the form [[min_a, max_a], [min_b, max_b], [min_c, max_c]]
            init_factor_bytes: initialization factor for maximum amount of bytes.
            init_factor_duration: initialization factor for maximum duration of flow (ms)
            init_factor_offline: initialization factor for maximum offline duration (ms)
            s_factor: factor for the small step size
            l_factor: factor for the large step size
            iter_mult: how often step_size should be multiplied by l_factor. iteration % iter_mult == 0
            max_no_impr: how many attempts should be tried unsuccessully before reducing the step_size by s_factor fractions.
        """
        step_size = list()
        step_size.append((bounds[0][1]-bounds[0][0]) * init_factor_bytes)
        step_size.append((bounds[1][1] - bounds[1][0]) * init_factor_duration)
        step_size.append((bounds[2][1] - bounds[2][0]) * init_factor_offline)
        current, count = {}, 0
        current["vector"] = self.random_vector(bounds)
        current["cost"] = self.objective_function(current["vector"], step_size)

        #print current["vector"], current

        for iter in range(max_iter):
            big_stepsize = self.large_step_size(iter, step_size, s_factor, l_factor, iter_mult)
            step, big_step = self.take_steps(bounds, current, step_size, big_stepsize)
            #print step, big_step
            # step, big_step are dictionaries that contain the estimated cost for that step
            if step["cost"] <= current["cost"] or big_step["cost"] <= current["cost"]:
                if big_step["cost"] <= step["cost"]:
                    step_size, current = big_stepsize, big_step
                else:
                    current = step
                count = 0
            else:
                count += 1
                count = 0
                if count >= max_no_impr:
                    step_size = [x / s_factor for x in step_size]
            print(" > iteration %d \t best=%d" % (iter+1, current["cost"]))
        return current

if __name__ == '__main__':
    pert = PerturbationOptimizer()
    print "Done. Best solution: c=%d" % pert.best["cost"]
    print pert.best["vector"]
